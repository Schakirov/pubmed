Пример запуска программы:
python analyze.py "2021-12-01" "2021-12-20"

Программа сгенерирует файл "pubmed-summary.html", со всеми статьями из пабмеда с 2021-12-01 по 2021-12-20, отсортированными по заданным Вами параметрам.
Пример сгенерированного программой файла Вы можете посмотреть уже сейчас.

Перед запуском программы нужно:
(1) установить pymed ("pip install pymed").
(2) скачать базу статей по ссылке 
Необязательно качать всю базу. Если Вы планируете искать только по 2021 году, можете скачать только часть базы за 2021 год.
Программа и сама умеет закачивать нужные файлы с pubmed, но это занимает много времени (несколько секунд на день).

!По всем вопросам работы программы пожалуйста свободно обращайтесь в личку https://www.facebook.com/shakirov.vladimir.9/ буду рад помочь, или просто обсудить программу.

Параметры можно менять в верхних строчках файла analyze.py
Какие бывают параметры:
(1) good_keywords. Запись 'glucosepane': 2.0 означает, что если слово 'glucosepane' будет найдено в абстракте статьи (1 или более раз), то к её итоговой оценке будет добавлено 2 балла. За вхождение этого слова в название статьи (1 или более раз) тоже добавляется 2 балла. Слова 'Glucosepane' или даже 'GlUcOZEpAne' тоже найдутся, и неважно, с большой или маленькой буквы Вы запишете это слово в good_keywords.
(2) bad_keywords. То же самое, но с отрицательными баллами. Соответственно, баллы отнимаются.
(3) bad_title_keywords. То же, что и bad_keywords, но применяются только к заголовку статьи.
(4) good_authors. Список авторов, чьи статьи Вы бы хотели видеть. За каждого автора даётся +10 баллов. Обычно этого хватает, чтобы статья оказалась наверху списка. 
(5) good_journals. То же, что good_keywords, но ищутся только в названии журнала.
(6) good_journals_strict. То же, что good_journals, но здесь ключевые слова должны точно совпадать с названием журнала (за исключением заглавности букв). 
(7) bad_journals. То же, что good_journals, но с отрицательными баллами.
(8) nArticlesInHtml = 5000. Число лучших статей, которые программа запишет в pubmed_summary.html

Примечание. Некоторые ключевые слова начинаются с 're:', например 're:gene therapy|genetic therapy': 1.0.
Это значит, что поиск будет производиться с использованием модуля re для поиска по регулярным выражениям. Подробнее про то, как составить регулярные выражения, можно почитать например здесь: https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285
В примере наверху это значит всего лишь, что будет искаться и 'gene therapy' и 'genetic therapy', но если найдутся оба, то статья всё равно получит только +1 балл. Потому что это по сути одно и то же. Вертикальная палочка '|' означает "ИЛИ".
Более сложный пример это 're:(?<=[^a-zA-Z])aging(?=[^a-zA-Z])': 1.0
Это нужно, чтобы исключить ложное нахождение слова aging, если в абстракте встретится например слово imaging или averaging.

И есть ещё два чуть более сложных параметра.
(8) good_keywords_max. То же самое, что и good_keywords, но с одним отличием.
Сейчас эта строчка имеет вид 
good_keywords_max = {'meta-analysis': 1.0, 'randomized controlled': 1.0, 'systematic review': 0.5, 'cochrane': 1.0, 'prospective': 0.3}
Если в абстракте статьи встретятся слова 'meta-analysis' и 'prospective', а в заголовке встретятся слова 'prospective' и 'systematic review', то за абстракт статья получит +1.0 балла (максимум от 1.0 и 0.3), а за заголовок ещё +0.5 балла (максимум от 0.3 и 0.5). Итого +1.5 балла.

Если бы это было good_keywords, а не good_keywords_max, то за абстракт статья получила бы 1.0 + 0.3 = 1.3 балла, а за заголовок ещё 0.3 + 0.5 = 0.8 баллов. Итого +2.1 балла.

(9) good_keywords_thresh. Разберем на примере. Сейчас эта строчка имеет вид:
good_keywords_thresh = {'mortality': [2.0, 3], 'collagen': [0.6, 2]}
Баллы за слово 'mortality' даются только в том случае, если слово 'mortality' встретилось 3 или более раз. Тогда даётся +2.0 балла.
К примеру, если в абстракте статьи слово 'mortality' встретилось 3 раза, а 'collagen' 1 раз, то к оценке статьи прибавится 2 балла.

Важно!
В первых двух строчках файла "analyze.py": 
your_tool_name = "SomeTool"
your_email = "SomeEmail@mail.ru"
желательно поменять email и имя. Они могут быть любыми, емейл не обязан быть существующим, но желательна их уникальность.
Эти данные используются модулем pymed для запросов в pubmed, и pubmed ведёт какую-то статистику этих запросов.

И ещё важно заметить вот какую вещь. База pubmed скажем за 10 декабря активно пополняется ещё несколько дней. Если 11 декабря провести поиск по этой дате, то программа скачает довольно немного статей. 12 декабря статей за 10 декабря будет уже больше, а на плато этот показатель выйдет еще через несколько дней. Поэтому поиск по новостям прошлой недели имеет ограниченный смысл, т.к. база pubmed за последние дни ещё пополняется. Это не недостаток программы, это свойство самой базы pubmed. Если Вы используете программу для сортировки вплоть до дня, в котором Вы находитесь, то желательно после этого удалить из папки data/ файлы, соответствующие последним нескольким датам, чтобы впоследствии программа скачала их полную версию (иначе она будет видеть, что файлы уже есть, и не станет их скачивать).

===
Более детальное описание работы программы для тех, кто захочет её улучшить:
(1) Очень хотелось бы, чтобы программа работала быстрее.
Сейчас она тратит около 3 минут на год. Терпимо (с учётом того, что выдаёт она 5000 статей, и даже беглый просмотр верхних 100 позиций всё равно займёт гораздо больше 3 минут), но наверняка можно быстрее.
Профилирование программы (python -m cProfile -s time analyze_new2.py "2021-12-01" "2021-12-26") показывает, что около половины времени работы уходит на строчку:
if_good = sum([d[keyword] for keyword in d.keys() if keyword in t])
Здеcь t - это текст (например, абстракт), а d - dictionary (например, good_keywords).
Хорошо бы реализовать более быстрый поиск десятков подстрок в одной строке.
Но вот например каждый раз строить суффиксное дерево для строки абстракта - скорее всего отнимет больше времени, чем будет выигрыш.
Можно предподсчитать суффиксные деревья и хранить их, но это в несколько раз увеличит размер файлов, а они и так очень большие.

(2) Несколько слов о том, как работает программа.
Главный цикл программы начинается строчкой
while curr <= date2:
Смысл этого цикла - это включение всех статей за текущую дату (curr) в текущий массив 5000 лучших статей.
В нём программа проверяет, есть ли файл за нужную дату, и если его нет, использует метод pubmed.query() для закачивания всех статей за данную дату с пабмеда. Метод pubmed.query() возвращает итератор, который далее превращается в list.
Просто list(iterator) не использую из-за memory error на датах с большим числом статей.
Попутно удаляется поле .xml из описания статьи. Оно очень большое, но вроде бы не содержит чего-то уникально полезного.
После чего запускается curr_articles = add_article(...), это главная функция, которая подсчитывает ценность статьи (по которой они потом будут сортироваться), вставляет в абстракт и заголовок <font> теги, и добавляет статью в словарь curr_articles.
И далее идёт несколько строчек, которые включают статьи за текущую дату в общий список всех набранных к этому времени статей таким образом, чтобы осталось только 5000 самых лучших статей (чтобы не было проблем с памятью).

Главная функция, которая подсчитывает ценность статьи и вставляет <font> теги html в абстракт и заголовок - это add_article(...).
Она вставляет <font> теги только когда её аргумент final=True, а final=True только в самом конце работы программы при формировании списка 5000 лучших статей, когда их pubmed_id уже известны.
Основную часть работы программы final=False, и функция только подсчитывает ценность статьи ('if-good').
Делается это посредством функций process, process_re, process_mult, process_thresh.
Эти функции возвращают подсчитанную часть ценности статьи и в случае final=True ещё возвращают массив с указанием мест в тексте, куда надо вставить теги выделения цветом '<font color="' + font_color + '">' и '</font>'. За их непосредственную вставку отвечает функция insert_font_tags(...). 
Поскольку поиск регулярных выражений идёт медленнее, чем обычный поиск, то при предварительном отборе 5000 статей регулярные выражения не учитываются. Они учитываются только при окончательной ранжировке отобранных 5000 статей (когда final=True).


